---
title: "Práctica 2: Limpieza y análisis de datos"
author: "*Luis Martin*"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  pdf_document:
    toc: true
    number_sections: true
    toc_depth: 3
  html_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_libraries, include=FALSE}
library(corrplot)
library(ResourceSelection)
library(pROC)
library(caret)
```

\newpage

# Detalles de la actividad

## Descripción

En esta práctica se elabora un caso práctico orientado a aprender a identificar los datos relevantes para un proyecto analítico y usar las herramientas de integración, limpieza, validación y análisis de las mismas.

## Objetivos

Los objetivos concretos de esta práctica son:

- Aprender a aplicar los conocimientos adquiridos y su capacidad de resolución de problemas en entornos nuevos o poco conocidos dentro de contextos más amplios o multidisciplinares.
- Saber identificar los datos relevantes y los tratamientos necesarios (integración, limpieza y validación) para llevar a cabo un proyecto analítico.
- Aprender a analizar los datos adecuadamente para abordar la información contenida en los datos.
- Identificar la mejor representación de los resultados para aportar conclusiones sobre el problema planteado en el proceso analítico.
- Actuar con los principios éticos y legales relacionados con la manipulación de datos en función del ámbito de aplicación.
- Desarrollar las habilidades de aprendizaje que les permitan continuar estudiando de un
modo que tendrá que ser en gran medida autodirigido o autónomo.
- Desarrollar la capacidad de búsqueda, gestión y uso de información y recursos en el
ámbito de la ciencia de datos.

## Competencias

En esta práctica se desarrollan las siguientes competencias del Máster de Data Science:

- Capacidad de analizar un problema en el nivel de abstracción adecuado a cada situación
y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.
- Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración,
transformación, limpieza y validación) para su posterior análisis.

\newpage

# Resolución

## Descripción del dataset

El conjunto de datos a analizar consiste en un set de atributos fisicoquímicos de muestras de vino rojo de variantes del vino portugués *"Vinho Verde"*. A cada una de estas muestras se le atribuye una puntuación en función de su calidad, que va de 0 a 10. El dataset se puede descargar desde este enlace en [*Kaggle*](https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009), está formado por 11 atributos mas la puntuación asociada a la calidad, y por un total de 1599 muestras o registros. 

A continuación se detallan las diferentes columnas del dataset:

- **fixed.acidity** (Acidez fija): ácidos involucrados con el vino o fijos o no volátiles (no se evaporan fácilmente). Principalmente ácido tartárico. Expresada en $g / dm^3$.
- **volatile.acidity** (Acidez volátil): ácidos volátiles presentes en el vino, principalmente ácido acético. A niveles altos puede provocar un sabor avinagrado en el vino. Expresada en $g / dm^3$.
- **citric.acid** (Ácido cítrico): Se usa en pequeñas cantidades para agregar frescura y sabor al vino. Expresado en $g / dm^3$.
- **residual.sugar** (Azúcar residual): Cantidad de azúcar residual una vez termina la fermentación. Expresado en $g / dm^3$.
- **chlorides** (Cloruros): Cantidad de cloruro sódico (sal) en el vino. Expresado en $g / dm^3$.
- **free.sulfur.dioxide** (Dióxido de azufre libre): Fracción de dióxido de azufre libre. Previene la proliferación de bacterias y la oxidación del vino. Expresado en $mg / dm^3$.
- **total.sulfur.dioxide** (Dióxido de azufre total): En concentraciones altas resalta la olor y el sabor del vino. Expresado en $mg / dm^3$.
- **density** (Densidad): Depende del porcentaje de alcohol y la concentración de azúcar. Expresada en $g / cm^3$.
- **pH** (pH): Describe cuán ácido o básico es un vino en una escala de 0 (muy ácido) a 14 (muy básico).
- **sulphates** (Sulfatos): Aditivo que contribuye a los niveles de dióxido de azufre. Expresado en $g / dm^3$.
- **alcohol** (Alcohol): Porcentaje de alcohol en el vino.
- **quality** (Calidad): Calidad de la muestra en una escala de 0 a 10, basada en la percepción sensorial.

## Importancia y objetivos de los análisis

Mediante este estudio se pretende averiguar cuáles son las principales características que influyen en la calidad de un vino rojo de la familia de vinos *"Vinho Verde"*. Por otro lado, elaborar y ajustar modelos de predicción que permitan determinar si un vino es de calidad a partir de sus propiedades fisicoquímicas, así como extraer características interesantes del dataset extrapolables al resto de la población. Los resultados de un estudio de este estilo pueden ser interesantes de cara a mejorar los procesos de elaboración de estos vinos para producir vinos de mejor calidad.

\newpage

## Limpieza de datos

Empezamos cargando el dataset y comprobando las dimensiones y la estructura de los datos. Además, podemos realizar un primer vistazo a los datos mediante un pequeño resumen estadístico.

```{r Load_DataSet}
# Cargar los datos
df.wines <- read.csv("winequality-red.csv")
```
```{r Str_DataSet}
# Estructura de los datos
str(df.wines)
```
```{r Summary_DataSet}
# Resumen estadístico
summary(df.wines)
```

\newpage

### Selección de los datos de interés

Dentro de nuestro conjunto de datos separamos los atributos en dos categorías, los atributos de entrada o explicativos, asociados a las 11 características fisicoquímicas de las muestras de vino, y un atributo de salida o dependiente, asociado a la variable que se pretende explicar, es decir, la calidad del vino. En un principio, todas las características del vino son susceptibles a provocar un impacto en la calidad, por lo tanto nos interesa conservar todos los atributos para estudiar y extraer información del conjunto de datos. En el momento de elaborar el modelo predictivo es posible que renunciemos a alguno de estos atributos debido a la colinealidad entre diferentes variables, pero esto es algo que dejaremos para mas adelante, cuando estudiemos las correlaciones. 

De cara a los análisis posteriores, nos interesaría incluir una nueva variable dicotómica que nos permita clasificar los vinos por calidad de una manera más sencilla, dividiéndolos entre buenos y malos. De este modo dividimos el conjunto de datos en dos grandes subgrupos y damos pié a un posible modelo de regresión logística.

```{r New_Variable}
# Variable calidad binaria
df.wines$bin_quality <- with(df.wines, ifelse(quality <= 6, 0, 1))
```

### Ceros y elementos vacíos

En el resumen estadístico, donde podemos observar el rango de valores que toma cada variable y la cantidad de valores nulos, vemos que todos los atributos caen dentro del dominio esperado y que no existen valores centinela para indicar la presencia de información perdida. El único atributo que contiene ceros en su rango es el ácido cítrico, pero se trata de un valor completamente plausible en cuanto a la composición de un vino. Por otro lado, tampoco detectamos la presencia de elementos vacíos, al parecer se trata de una dataset ya limpio y preparado para el análisis. 

En el caso hipotético de que hubiésemos detectado información perdida se debería haber reemplazado estos datos con medidas de tendencia central o imputar los valores implementando métodos de predicción como *K-Nearest Neighbours* o *missForest*. 

```{r NA_Values}
# Números de valores desconocidos por campo
sapply(df.wines, function(x) sum(is.na(x)))
```

\newpage

### Valores extremos

Se considera *outliers* todos aquellos valores que se encuentran muy alejados de la media de la población. En función de su origen deben tratarse de un modo u otro. En ocasiones son debido a una desviación sistemática en la obtención de los datos y es fácilmente remediable mediante una operación sencilla. En otras ocasiones son medidas completamente legítimas de valores atípicos de la población, en ese caso deben contemplarse dentro del análisis. Los diagramas de caja a continuación muestran la presencia de una gran cantidad de *outliers* en los diferentes atributos, aún así, se trata de valores legítimos que entran dentro del rango de posibles valores que podrían tomar estas características. Deben dejarse como están y tenerse en consideración en el posterior análisis. 

```{r BoxPlots}
# BoxPlots
par(mfrow=c(3,4), mar=c(1,2,1,1))
boxplot(df.wines$fixed.acidity, main="fixed.acidity")
boxplot(df.wines$volatile.acidity, main="volatile.acidity")
boxplot(df.wines$citric.acid, main="citric.acid")
boxplot(df.wines$residual.sugar, main="residual.sugar")
boxplot(df.wines$chlorides, main="chlorides")
boxplot(df.wines$free.sulfur.dioxide, main="free.sulfur.dioxide")
boxplot(df.wines$total.sulfur.dioxide, main="total.sulfur.dioxide")
boxplot(df.wines$density, main="density")
boxplot(df.wines$pH, main="pH")
boxplot(df.wines$sulphates, main="sulphates")
boxplot(df.wines$alcohol, main="alcohol")
boxplot(df.wines$quality, main="quality")
```

### Exportación de los datos

Tras validar y limpiar los datos guardamos el dataset con la nueva columna que etiqueta los vinos en buenos y malos en función de su calidad. 

```{r Save_DataSet}
# Guardar los datos
write.csv(df.wines, "winequality-red-clean.csv")
```

## Análisis de los datos

### Selección de los grupos de datos a analizar

Dividimos las muestras en dos subgrupos utilizando el atributo *bin_quality* para poder comparar las propiedades fisicoquímicas de los vinos de buena calidad con los de mala calidad. 

```{r Subgrupos}
# Agrupación por calidad
df.wines.good <- df.wines[df.wines$bin_quality==1,]
df.wines.bad <- df.wines[df.wines$bin_quality==0,]
```

### Distribución de las variables

Realizamos los histogramas de las variables con las distribuciones de densidad de las dos poblaciones para un primer acercamiento a la distribución de los datos.

```{r hist, echo=FALSE}
# Histogramas
par(mfrow=c(3,4), mar=c(4,4,1,1))

hist(df.wines$fixed.acidity, main="fixed.acidity",  xlab="", freq = FALSE)
lines(density(df.wines.good$fixed.acidity), col="blue") 
lines(density(df.wines.bad$fixed.acidity), col="red")
legend("topright", c("good", "bad"),lty = 1, col = c("blue", "red"), cex=0.65)

hist(df.wines$volatile.acidity, main="volatile.acidity",  xlab="", freq = FALSE)
lines(density(df.wines.good$volatile.acidity), col="blue") 
lines(density(df.wines.bad$volatile.acidity), col="red")
legend("topright", c("good", "bad"),lty = 1, col = c("blue", "red"), cex=0.65)

hist(df.wines$citric.acid, main="citric.acid",  xlab="", freq = FALSE)
lines(density(df.wines.good$citric.acid), col="blue") 
lines(density(df.wines.bad$citric.acid), col="red")
legend("topright", c("good", "bad"),lty = 1, col = c("blue", "red"), cex=0.65)

hist(df.wines$residual.sugar, main="residual.sugar",  xlab="",  freq = FALSE)
lines(density(df.wines.good$residual.sugar), col="blue") 
lines(density(df.wines.bad$residual.sugar), col="red")
legend("topright", c("good", "bad"),lty = 1, col = c("blue", "red"), cex=0.65)

hist(df.wines$chlorides, main="chlorides",  xlab="", freq = FALSE)
lines(density(df.wines.good$chlorides), col="blue") 
lines(density(df.wines.bad$chlorides), col="red")
legend("topright", c("good", "bad"),lty = 1, col = c("blue", "red"), cex=0.65)

hist(df.wines$free.sulfur.dioxide, main="free.sulfur.dioxide",  xlab="",  freq = FALSE)
lines(density(df.wines.good$free.sulfur.dioxide), col="blue") 
lines(density(df.wines.bad$free.sulfur.dioxide), col="red")
legend("topright", c("good", "bad"),lty = 1, col = c("blue", "red"), cex=0.65)

hist(df.wines$total.sulfur.dioxide, main="total.sulfur.dioxide", xlab="", freq = FALSE)
lines(density(df.wines.good$total.sulfur.dioxide), col="blue") 
lines(density(df.wines.bad$total.sulfur.dioxide), col="red")
legend("topright", c("good", "bad"),lty = 1, col = c("blue", "red"), cex=0.65)

hist(df.wines$density, main="density", xlab="", freq = FALSE)
lines(density(df.wines.good$density), col="blue") 
lines(density(df.wines.bad$density), col="red")
legend("topright", c("good", "bad"),lty = 1, col = c("blue", "red"), cex=0.65)

hist(df.wines$pH, main="pH", xlab="", freq = FALSE)
lines(density(df.wines.good$pH), col="blue") 
lines(density(df.wines.bad$pH), col="red")
legend("topright", c("good", "bad"),lty = 1, col = c("blue", "red"), cex=0.65)

hist(df.wines$sulphates, main="sulphates", xlab="", freq = FALSE)
lines(density(df.wines.good$sulphates), col="blue") 
lines(density(df.wines.bad$sulphates), col="red")
legend("topright", c("good", "bad"),lty = 1, col = c("blue", "red"), cex=0.65)

hist(df.wines$alcohol, main="alcohol", xlab="", freq = FALSE)
lines(density(df.wines.good$alcohol), col="blue") 
lines(density(df.wines.bad$alcohol), col="red")
legend("topright", c("good", "bad"),lty = 1, col = c("blue", "red"), cex=0.65)
```

\newpage

### Comprobación de la normalidad 

Utilizaremos el test de *Shapiro-Wilk* con un nivel de significancia $\alpha=0.05$ para comprobar la normalidad de los atributos fisicoquímicos del vino. En esta prueba la hipótesis nula asume normalidad, por tanto, un valor p menor al nivel de significancia rechaza la normalidad en los datos. El principal objetivo de esta sección es conocer la distribución de valores de cada atributo para determinar qué tests estadísticos será conveniente utilizar durante el análisis. Estudiar cada población por separado será más efectivo de cara a escoger los tests para los contrastes de hipótesis.

```{r Shapiro-Wilk good}
# Shapiro-Wilk test good wines
alpha <- 0.05
col.names <- colnames(df.wines.good)

#Variables que siguen una distribución normal
normal = c()
for (i in 1:(ncol(df.wines.good)-2)) {
  p_val <- shapiro.test(df.wines.good[,i])$p.value
  if (p_val > alpha) {
    normal <- c(normal, col.names[i])
  }
}

print(normal)
```

```{r Shapiro-Wilk bad}
# Shapiro-Wilk test bad wines
alpha <- 0.05
col.names <- colnames(df.wines.bad)

#Variables que siguen una distribución normal
normal = c()
for (i in 1:(ncol(df.wines.bad)-2)) {
  p_val <- shapiro.test(df.wines.bad[,i])$p.value
  if (p_val > alpha) {
    normal <- c(normal, col.names[i])
  }
}

print(normal)
```

En general las variables no siguen una distribución normal. Aún así, debemos destacar que ambas poblaciones están formadas por centenares de muestras, y podemos asumir gracias al **Teorema del Limite Central** que las medias muestrales sí que siguen una distribución normal.

\newpage

### Comprobación de la homogeneidad de la varianza

Dado que los datos que queremos comparar no siguen una distribución normal aplicaremos el test *Fligner-Killeen* para comprobar si existe homocedasticidad entre los atributos de ambas poblaciones. En este test la hipótesis nula asume igualdad de varianzas, por lo tanto, un valor p menor a $\alpha=0.05$ concluye que la diferencia en las varianzas es estadísticamente significativa. 

```{r Fligner-Killeen}
# Fligner-Killeen test 
alpha <- 0.05
col.names <- colnames(df.wines)

#Variables con igualdad de varianzas
eq.varianzas = c()
for (i in 1:(ncol(df.wines)-2)) {
  p_val <- fligner.test(df.wines[,i] ~ df.wines$bin_quality)$p.value
  if (p_val > alpha) {
    eq.varianzas <- c(eq.varianzas, col.names[i])
  }
}

print(eq.varianzas)
```

El ácido cítrico, el azúcar residual, los cloruros, el pH, los sulfatos y la concentración de alcohol comparten varianza entre ambas poblaciones. 

## Pruebas estadísticas

### Contraste de hipótesis 

Queremos comprobar si la graduación, la concentración de sulfatos y la concentración de cítricos es mayor en los vinos de buena calidad. Para ello disponemos de dos poblaciones independientes de tamaño suficiente para aplicar el **Teorema del Limite Central** y con homocedasticidad. El test estadístico correspondiente es un T-student unilateral y la formulación de las hipótesis es:

\begin{center}
$H_0: \mu_{bueno} = \mu_{malo}$

$H_1: \mu_{bueno} > \mu_{malo}$
\end{center}

```{r t-st_alcohol}
# Contraste de hipótesis para el porcentaje de alcohol
 t.test(df.wines.good$alcohol, df.wines.bad$alcohol,
        alternative = "greater", var.equal=TRUE)
```

\newpage

```{r t-st_sulfatos}
# Contraste de hipótesis para la concentración de sulfatos
 t.test(df.wines.good$sulphates, df.wines.bad$sulphates,
        alternative = "greater", var.equal=TRUE)
```

```{r t-st_cítricos}
# Contraste de hipótesis para la concentración de ácido cítrico
 t.test(df.wines.good$citric.acid, df.wines.bad$citric.acid,
        alternative = "greater", var.equal=TRUE)
```

En los tres casos el valor p es inferior a $\alpha=0.05$ y por tanto podemos rechazar la hipótesis nula con un 95% de confianza. Podemos afirmar con un nivel de significancia $\alpha=0.05$ que los vinos de buena calidad tienen un mayor porcentaje de alcohol, una mayor concentración de sulfatos y mayor concentración de ácido cítrico, responsables de añadir más frescura y sabor y evitar su oxidación. 

\newpage

### Correlaciones

Para estudiar la correlación entre las variables no podemos recurrir al coeficiente de correlación lineal de *Pearson* debido que los datos no siguen una distribución normal. El coeficiente de correlación de *Spearman* es la alternativa no paramétrica. Mide el grado de dependencia entre dos variables sin asumir ningún tipo de suposición sobre la distribución de los datos. 

Tras calcular la matriz de correlación vemos que los factores que más influyen positivamente en la calidad del vino son el porcentaje de alcohol y la concentración de sulfatos, mientras que la acidez volátil lo hace negativamente. También observamos la relación que mantienen las variables explicativas entre si: la densidad depende en gran medida de otras variables como el alcohol, los ácidos fijos y el azúcar residual; el pH depende sobretodo de el ácido cítrico y los ácidos fijos; y el dióxido de azufre total está altamente relacionado con el dióxido de azufre libre. Deberíamos tener en cuenta estas relaciones si queremos obtener información útil de los regresores al elaborar un modelo de regresión logística debido a la multicolinealidad entre las variables explicativas. De todos modos, en general no se trata de correlaciones con un coeficiente demasiado alto.   

```{r Correlation, fig.align = "center"}
M <- cor(df.wines[,-length(df.wines)], method = "spearman")

corrplot(M, method="color", type="upper", cl.cex=0.5, 
         order="hclust", addCoef.col = "black",
         number.cex = .5, tl.col="black", tl.cex=0.5)
```

\newpage

### Modelo de regresión logística

Finalmente, y aprovechando los conocimientos que hemos deducido de los demás apartados, crearemos un modelo de regresión logística para predecir si un vino es de bueno calidad en función de las características que tienen más impacto. Dividmios los datos en train y test para posteriormente evaluar el modelo.

```{r Modelo}
# Test y Train sets
set.seed(123)
training.samples <- createDataPartition(df.wines$bin_quality, p = 0.7, list = FALSE)
train.data  <- df.wines[training.samples, ]
test.data <- df.wines[-training.samples, ]

# Ajuste de un modelo logístico.
model <- glm(bin_quality ~ alcohol + sulphates + volatile.acidity,
                        data = train.data, family = "binomial")

# Resumen
summary(model)
```

Todos los regresores son estadísticamente significativos y el valor de AIC ronda los 700. Cuando los regresores son positivos los factores se denominan factores de riesgo. Estos factores influyen en la desviación hacia el factor que no es el de referencia, en nuestro caso, el vino de calidad. Recuperamos, por tanto, los resultados obtenidos en el apartado anterior sobre la correlación, que nos decía que el porcentaje de alcohol y la concentración de sulfatos afectan positivamente a la calidad del vino. 

\newpage

Para calcular la capacidad de diagnóstico del modelo comparamos los valores estimados del conjunto de test con los valores registrados. Obtenemos que el modelo clasifica correctamente el 90% de los datos cuando el umbral de discriminación es 0.5.

```{r accuracy}
# Make predictions
probabilities <- predict(model, test.data, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)

# Model accuracy
mean(predicted.classes == test.data$bin_quality)
```

Para calcular la bondad del ajuste también podemos realizar un test *Hosmer-Lemeshow*, que se usa en modelos lineales generalizados con distribución binomial. La hipótesis nula de este test asume que no existe diferencia estadística entre los valores observados y los valores estimados. El valor p es mayor al nivel de significancia $\alpha=0.05$, por tanto no podemos rechazar la hipótesis nula. No existe diferencia estadística entre los valores observados y los valores estimados, lo que significa que el modelo está bien ajustado.

```{r Bondad del ajuste}
#Test Hosmer-Lemeshow
hoslem.test(train.data$bin_quality,fitted(model))
```

Análogamente, podemos dibujar la curva ROC, que muestra la relación entre la sensibilidad y la especificidad para diferentes umbrales de discriminación. Cuanto mayor sea el área bajo la curva mejor será el valor de diagnóstico del modelo.

```{r ROC, message=FALSE, fig.height = 3, fig.width = 3, fig.align = "center"}
# Curva Roc
r=roc(train.data$bin_quality, model$fitted.values)
plot(r)

# Area bajo la curva
auc(r)
```

### Cross Validation 

Podemos intentar entrenar el modelo utilizando validación cruzada. En este método todas las observaciones se usan tanto para entrenar como testear el modelo la misma cantidad de veces. 

```{r CrossValidation, warning=FALSE, message=FALSE, fig.height = 3, fig.width = 3, fig.align = "center"}
# Train control
train_control <- trainControl(method = "cv", number = 10)

# Entrenamos el modelo
modelCV <- train(bin_quality ~ alcohol + sulphates + volatile.acidity,
               data = df.wines, method = "glm",
               trControl = train_control)

# Make predictions
probabilities <- predict(modelCV)
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)

# Model accuracy
mean(predicted.classes == df.wines$bin_quality)

# Curva Roc
r=roc(df.wines$bin_quality, probabilities)
plot(r)

# Area bajo la curva
auc(r)
```

Obtenemos un modelo muy similar al anterior. La precisión del modelo para los datos de la muestra es ligeramente menor, pero gracias a la validación cruzada conseguimos un modelo con una capacidad de diagnóstico ligeramente superior. 

\newpage 

## Conclusiones

Hemos estudiado cuáles son las principales características que influyen en la calidad de un vino tinto de la variedad *"Vinho Verde"*. Tras limpiar el conjunto de datos se han realizado un conjunto de pruebas estadísticas. Para conocer las diferencias entre los vinos de buena y mala calidad se han ejecutado un seguido de contrastes de hipótesis que nos permiten extrapolar los resultados extraídos de nuestra muestra al resto de la población. A continuación, se ha estudiado las relaciones entre la calidad y las variables explicativas, así como las relaciones entre las diferentes variables independientes, mediante la correlación de *Spearman*, test que se puede aplicar sin asumir una distribución en los datos. Finalmente, utilizando los conocimientos previos se han ajustado un par de modelo de regresión logística para predecir si un vino es de buena calidad basándose en su composición y se ha comprobado que estén bien ajustados. El modelo entrenado mediante validación cruzada consigue una capacidad de diagnóstico ligermaente superior.

# Recursos

- P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.

- Calvo M., Subirats L., Pérez D. (2019). Introducción a la limpieza y análisis de los datos. Editorial UOC.

- Bernadó E. (2020). Contrastes de hipótesis. Editorial UOC.

- Guillén M., Alonso M. (2020). Modelos de regresión logística. Editorial UOC.